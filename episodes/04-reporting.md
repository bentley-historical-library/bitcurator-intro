---
title: 'Reporting'
teaching: 5
exercises: 3
---

:::::::::::::::::::::::::::::::::::::: questions 

- What tools are available in the BitCurator environment for analyzing disk images or directories of data tranferred from legacy media?
- How can librarians and archivists capture basic system characteristics and metadata?
- How can they scan for for potentially sensitive information?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Gain experience with:
  - Brunnhilde, a reporting tool for directories and disk images;
  - Bulk Extractor and Bulk Reviewer, which scans for credit card numbers, emails, etc.; and
  - `fiwalk`, to print filesystem statistics
- Discover ways to learn more about the reporting functionality in the BitCurator Environment.

::::::::::::::::::::::::::::::::::::::::::::::::

Reporting in BitCurator is essentially a method of generating technical and preservaiton metadata about a disk image or directory of data.

At a high level, you will be using, and creating a workflow piecing together:
- a "map" of the disk image, which records relationships, integrity (checksums), names, timestamps, etc. (this is in DFXML); 
- a summary of the file types, duplicates, and other relationship information;
- tools for assessing Personally Identifialble Information (PII) and sensitive content; and 
- summaries of sensitive content, if discovered.

_**Note:** If you haven't yet created a disk image or otherwise have a directory of data to work with, you can download sample data from BitCurator's Github site and work with that: [bcc-dfa-sample-data](https://github.com/bitcurator/bcc-dfa-sample-data)._

One possible structure to group content and metadata:

```
c4l24_bicuratorintro_group0X_image0XX/              <-- parent directory (sample name)
│
├── reports/                                        <-- subdirectory for detailed metadata (use mkdir)
│   ├── beout/				                        <-- bulk extractor reports (generated by bulk_extractor)
│   ├── brunn_output/		                        <-- brunnhilde reports (generated by brunnhilde.py)
│   └── mappedfeatures/                             <-- sensitive info (generated by identify_filenames.py)
│
├── c4l24_bicuratorintro_group0X_image0XX_dfxml.xml <-- DFXML (E01 “map” generated by fiwalk)
├── c4l24_bicuratorintro_group0X_image0XX.E01 		<-- disk image (generated by Guymager)
└── c4l24_bicuratorintro_group0X_image0XX.info      <-- disk image metadata (from Guymager)	
```

First Things First

A simply way to get usage instructions for any of the following tools is to simply type their names in the terminal and press enter. E.g., `fiwalk`, which is the same as as using `fiwalk -h` or `fiwalk --help`.

## Reporting

BitCurator includes a variety of tools to analyze and report on disk images and the filesystems they contain.

### Map Your Image AKA How to Create DFXML (with fiwalk)

Your first goal is to create a DFXML "map" of the disk image. This will include all filesystem data, checksums for integrity, and explain the relationships of elements of the disk image. 

**Tool:** fiwalk

**To run:** Use fiwalk in the terminal.

**Command syntax:**

```
fiwalk -f -X <output filename> <input image file> 
```

This command tells the terminal to run `fiwalk`, run the "file" command on each file that it finds (`-f`), write the results to an XML file with the specified filename (`-X <output filename>`) and identifies the source of the analysis (the EWF image).

### File Summaries and Reports AKA How to Run brunnhilde to Report on the Disk Image

Your next goal is to create a summary of file types, duplicates, and any hard to identify files. 

**Tool:** brunnhilde

**To run:** Use brunnhilde in the terminal.

**Command syntax:**

```
brunnhilde.py -d -b --tsk_fstype fat --tsk_imgtype ewf <image input file> <output destination> 
```

This command tells the terminal to run `brunnhilde`, treat the input as a disk image (`-d`), generate a bulk extractor report (`-b`), analyze the disk image as an FAT filesystem (`--tsk_fstype fat`), and analyze the disk image as an expert witness file (`--tsk_imgtype ewf`). Then, the command provides the location of the source disk image (`<image input file>`) and the destination for reports (`<output destination>`).

### Identify Sensitive Information AKA How to Identify Features (with bulk_extractor)

Your next goal is to create reports that identify potentially sensitive information, like SSNs, emails, etc.

**Tool:** bulk_extractor

**To run:** Use bulk_extractor in the terminal AND/OR use Bulk Reviewer.

**Command syntax:**

```
bulk_extractor -o <output destination> <input target disk image file>  
```

This command tells the terminal to run the `bulk_extractor` tool, then to output a report to the specified directory (`-o <image directory>/reports/beout`) and specifies the target file to analyze (`<input target disk image file>`).

_**Note:** To use Bulk Reviewer, click over Applications (top left) > Forensics and Reporting > bulk-reviewer. Click "Scan new directory or disk image." Select the "Type" ("Directory" or "Image"), create a "Name" for the report, "Browse" to the directory or disk image, select and "Options" and then click "Start Scan." Once it's finished, you can then view the report and have options to save or export the results._

_**Note:** The "terry-work-usb-2009-12-11.EO1" disk image in the sample data from BitCurator's Github site produces a number of "hits"--including social security numbers, phone numbers, and email addresses--if the directories or disk images you're working with do not._

### Summarize Sensitive Information Reports AKA How to Summarize Identified Features (with identify_filenames.py)

Your final goal is to summarize the reports on sensitive information, show main types of features, and to note what files contain the features.

**Tool:** identify_filenames.py

**To run:** Use identify_filenames in the terminal.

**Command syntax:**

```
identify_filenames.py --all --image_filename <input disk image> --xmlfile <DFXML of the image> <bulk extractor reports location> <destination for summary report>  
```

This command tells the terminal to run the `identify_filenames.py` script, look at all of the feature files (`--all`), specifies the source image (`--image_filename <input disk image>`), use the specified DFXML file (`--xmlfile <DFXML of the image>`), identifies the bulk extractor output to use (`<bulk extractor reports location>`, use the one in `<image directory>/reports/brunn_outputs/bulk_extractor`), and specifies a destination for the the analysis (`<image directory>/reports/mappedfeatures`).

## So What?

include info from planning doc
Are we explaining the “so what?” and what you may use reports for, how useful are they, etc?
Characterizing it more as creation of technical/preservation metadata
Some reports may be needed for contextualizing and using the disc images in other programs (dfxml)
Some reports may be more for risk management and analyzing PII
Some may be more for preservation planning (file types)
Some may be for general description (dates of creation, titles/names of files, users, or other topical information)
	

## Additional resources
